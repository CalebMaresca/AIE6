{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/49.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/233.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m378.1/378.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-loyal-feedback-91\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-13 20:01:58--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: â€˜john_wick_1.csvâ€™\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-05-13 20:01:58 (11.7 MB/s) - â€˜john_wick_1.csvâ€™ saved [19628/19628]\n",
            "\n",
            "--2025-05-13 20:01:58--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_2.csvâ€™\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-05-13 20:01:59 (5.05 MB/s) - â€˜john_wick_2.csvâ€™ saved [14747/14747]\n",
            "\n",
            "--2025-05-13 20:01:59--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_3.csvâ€™\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-13 20:01:59 (97.5 MB/s) - â€˜john_wick_3.csvâ€™ saved [13888/13888]\n",
            "\n",
            "--2025-05-13 20:01:59--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: â€˜john_wick_4.csvâ€™\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-05-13 20:01:59 (7.95 MB/s) - â€˜john_wick_4.csvâ€™ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunkSizes = []\n",
        "for doc in documents:\n",
        "    chunkSizes.append(len(doc.page_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 17, 10, 12, 43, 899754)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example list of integers\n",
        "data = chunkSizes\n",
        "\n",
        "# Create x-axis values (indices of the list)\n",
        "x = range(len(data))\n",
        "\n",
        "# Plot vertical lines for each integer\n",
        "for i, value in enumerate(data):\n",
        "    plt.plot([i, i], [0, value], 'b-')  # 'b-' means blue line\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Vertical Lines for List Values')\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. Several reviews highly praise the film, with ratings of 8, 9, or 10 out of 10, and describe it as stylish, fun, and a standout action movie. There is one review with a lower rating of 5 or 6, expressing some confusion or less enthusiasm, but overall, the sentiment is mostly positive. Therefore, it is fair to say that people generally liked John Wick.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n\\n1. Review Title: \"A Masterpiece & Brilliant Sequel\"  \\n   URL: /review/rw4854296/?ref_=tt_urv\\n\\n2. Review Title: \"love this movie highly recommend\"  \\n   URL: /review/rw5503708/?ref_=tt_urv'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the film \"John Wick,\" the story follows a retired hitman (played by Keanu Reeves) who seeks revenge after his beloved dog is killed, his house is destroyed, and his car is stolen by some gangsters led by a young Russian punk. The incident triggers Wick\\'s return to his deadly past, as he unleashes a brutal and meticulously choreographed assault against those responsible. Throughout the series, Wick is depicted as a highly skilled assassin with a dark, violent world surrounding him. As the story progresses across multiple films, Wick\\'s actions often lead to dangerous consequences, involving criminal underworld organizations, such as the Russian Mafia, the Italian criminal factions, and the mysterious high-table leadership, creating a complex narrative of revenge, loyalty, and the consequences of violence.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people have generally liked the John Wick movies, especially the first one, which received high ratings and positive comments about its style, action, and storytelling. However, opinions on the later films are more mixed, with some viewers expressing dissatisfaction with aspects like plot and violence. Overall, it appears that many viewers appreciated the franchise, but there are also some negative opinions.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided reviews, there are no reviews with a rating of 10.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick series, the main storyline follows John Wick, a legendary assassin who is drawn back into the dangerous underworld after a series of events. The first movie, \"John Wick,\" depicts how Wick\\'s peaceful life is disrupted when thieves steal his car and kill his dog, a gift from his deceased wife. This tragedy motivates him to seek revenge against those who wronged him, leading to intense action and battles with other assassins and criminal organizations.\\n\\nThroughout the series, John Wick is portrayed as a highly skilled and unstoppable fighter, navigating a world filled with violence, secret societies, and complex codes of conduct. The movies are known for their choreographed action scenes, emotional depth, and a detailed depiction of the assassin society\\'s rules and customs.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people generally liked John Wick. The reviews are highly positive, praising its action sequences, style, and Keanu Reeves' performance, with ratings of 9 and 10 out of 10. However, there are some mixed opinions for the third film, with a rating of 5, indicating that not all viewers felt the same way. Overall, the majority of the reviews suggest that people generally enjoyed the film series.\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n\\n1. Review titled \"A Masterpiece & Brilliant Sequel\" for John Wick 3: [https://john_wick_3.csv/review/rw4854296/?ref_=tt_urv](#)\\n\\n2. Review titled \"Most American action flicks released these days have poor screenplays and overuse computer-generated imagery\" for John Wick 3: [https://john_wick_3.csv/review/rw4860412/?ref_=tt_urv](#)'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick series, the story begins with John Wick, a retired hitman, seeking peace after the death of his wife. However, his life changes dramatically when a group of gangsters steal his car and kill his dog, which was a gift from his wife. This act drags Wick back into the violent world he tried to leave behind, and he unleashes a relentless vendetta against those responsible.\\n\\nIn the subsequent events, Wick's past actions come into play when a mobster named Santino D'Antonio shows up, demanding Wick's help with a favorâ€”a marker that binds Wick to certain obligations. Wick initially refuses but is eventually persuaded to kill Santino's sister to help him sit on the High Table of criminal organizations. After completing this task, Santino betrays Wick by putting a contract on him, making him a target for many professional killers. This sets off a fierce and deadly pursuit as Wick fights to survive and confront his past.\\n\\nOverall, the series is known for its intense action, stylish combat sequences, and a plot centered around revenge and the consequences of a violent life.\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews in the provided context, people generally liked John Wick. The majority of reviews are quite positive, praising the film\\'s action sequences, style, and entertainment value. For example, some reviews rated it as high as 9 or 10 out of 10 and described it as a \"must-see\" or \"slick, violent fun.\" Even some moderate ratings acknowledge its strong action choreography and entertainment appeal. \\n\\nHowever, there are a few negative reviews, but these are in the minority. Overall, the general consensus seems to be that people found John Wick to be an exciting, well-made action film that is highly appreciated by its audience.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is at least one review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick film series, the story centers around John Wick, a retired assassin who is drawn back into the world of violence and revenge. The first film (2014) depicts how Wick seeks vengeance after gangsters kill his dog and steal his car, which reignites his lethal skills and reputation. Throughout the series, Wick faces various enemies, including Russian mobsters and professional killers, while navigating a secret world of assassins with its own rules and society. The films showcase his relentless pursuit of retribution, intense action sequences, and the consequences of violence in this underground world.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_25125/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people\\'s opinions on John Wick vary. Some reviews are highly positive, praising the series and the movies, with one reviewer calling it \"the ride of your life\" and suggesting it is highly recommended. However, there is also at least one negative review describing the movie as \"HORRIBLE\" with strong criticisms about the plot and fight scenes. Overall, the reception seems mixed, with some viewers liking the films and others not enjoying them.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick movies, John Wick is a retired assassin who initially comes out of retirement after the death of his dog and the theft of his car, which leads to a violent rampage. In the first film, he seeks revenge against those who wronged him, unleashing a series of deadly confrontations. The second film continues his story, where he is compelled to help an old friend and gets involved in a complex situation involving the Assassin's Guild, taking him across various locations and involving numerous conflicts with other assassins.\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. Many reviews are highly positive, praising its stylish action, choreography, and entertainment value. For example, reviews with ratings of 8, 9, or even 10 reflect strong approval. However, there are some mixed and negative opinions as well, with a few reviewers giving low ratings and criticizing aspects like plot, believability, or over-the-top violence. Overall, the majority of reviews are favorable, indicating that people generally appreciated the film, especially fans of action movies.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. The URLs for those reviews are:\\n\\n1. /review/rw4854296/?ref_=tt_urv\\n2. /review/rw4860412/?ref_=tt_urv'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick series, the story revolves around John Wick, a retired assassin who is drawn back into the world of violence and revenge. The first film details how Wick comes out of retirement after gangsters kill his dog and steal his car, which reignites his lethal skills as he seeks vengeance. The subsequent movies explore his ongoing conflicts with various criminal organizations, his efforts to pay off debts and adhere to the rules of the assassin community, and the repercussions of his actions. Throughout the series, Wick becomes a legendary figure feared by many, engaging in intense action sequences and demonstrating a relentless pursuit of retribution.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. The reviews are largely positive, praising its action, style, and entertainment value. For example, some reviews gave high ratings like 9 and 10 out of 10, indicating strong approval. However, there are a few mixed or negative opinions, such as a review giving a 0 rating and mentioning a lack of urgency. Overall, the majority of reviews suggest that people generally liked the John Wick movies.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick movies, the story centers around a retired assassin named John Wick, played by Keanu Reeves. In the first film, John Wickâ€™s peaceful life is shattered when a group of thugs, led by the son of a Russian gangster he used to work for, break into his house, beat him up, steal his car, and kill his beloved dog, which was a gift from his late wife. This act of violence prompts Wick to come out of retirement to seek vengeance. The film depicts his relentless quest for revenge against those who wronged him, leading to a series of violent confrontations with criminal organizations, hitmen, and mobsters. Throughout the series, John Wick is portrayed as a highly skilled and ruthless assassin, with each movie exploring the consequences of his actions and the dangerous underworld he navigates.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up LangSmith tracing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Make test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6da39ec2c61c4c5a9c0dd97db476544e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aeb9a54e36d4c23b5c81fc98535376d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 78a61373-c0d5-4f12-b23a-655bcf82af10 does not have a summary. Skipping filtering.\n",
            "Node 13c1611f-9001-46ee-a423-79e51b280767 does not have a summary. Skipping filtering.\n",
            "Node d61886a1-f7bc-4f7a-979f-a01f38e7909b does not have a summary. Skipping filtering.\n",
            "Node db08b8a0-3c6e-497e-9d11-43e0eadefd32 does not have a summary. Skipping filtering.\n",
            "Node 4671ac00-68c4-44c9-9775-e1a1a64214fa does not have a summary. Skipping filtering.\n",
            "Node bf6b78f6-fcf0-4a31-916f-563516de629b does not have a summary. Skipping filtering.\n",
            "Node 79bf089e-c8b0-4306-b8c7-c730886a3bfb does not have a summary. Skipping filtering.\n",
            "Node 1b8ba34d-8dc0-4cce-960d-1b582956c0f8 does not have a summary. Skipping filtering.\n",
            "Node aa0595ce-ff1d-4766-beae-2b9739461259 does not have a summary. Skipping filtering.\n",
            "Node dade144b-3488-48ac-b0f3-b101426668f2 does not have a summary. Skipping filtering.\n",
            "Node cef288ac-66b0-4a79-900c-ef895b78f6ac does not have a summary. Skipping filtering.\n",
            "Node f14ff695-716a-43a2-8da3-8f2fdaf9675a does not have a summary. Skipping filtering.\n",
            "Node 51c13918-f154-46c7-8eab-39c71fc8842c does not have a summary. Skipping filtering.\n",
            "Node 6d7c0d06-7318-4f1b-bdbe-e36dbd12b216 does not have a summary. Skipping filtering.\n",
            "Node 97562d5f-1527-4b43-b1e2-e7acd967be13 does not have a summary. Skipping filtering.\n",
            "Node 51a5ae68-b0d4-435d-a106-b24a6870f09e does not have a summary. Skipping filtering.\n",
            "Node fd8bf79e-9081-42f1-b8f1-e14ff0fa8ad5 does not have a summary. Skipping filtering.\n",
            "Node adc6e068-304d-498d-8b56-5957f54a3184 does not have a summary. Skipping filtering.\n",
            "Node f9b3a064-5a7f-40d5-8955-bf1e6d73004e does not have a summary. Skipping filtering.\n",
            "Node 2d8229e9-d2f4-473e-93fa-555e9c51f929 does not have a summary. Skipping filtering.\n",
            "Node 9243166b-e4c4-4514-8fad-257b9333a069 does not have a summary. Skipping filtering.\n",
            "Node cc7571c8-f9ab-4a2c-a168-fe63801ec458 does not have a summary. Skipping filtering.\n",
            "Node bb0a64f4-54a3-42ec-ba80-bfd0247da729 does not have a summary. Skipping filtering.\n",
            "Node 9db95d91-4aa6-41b5-96c0-09b1afa88aef does not have a summary. Skipping filtering.\n",
            "Node f99f4e9f-9e72-4267-a1c6-a40944c6f88e does not have a summary. Skipping filtering.\n",
            "Node 2330403d-db7b-4e89-a093-8e9e79661f4f does not have a summary. Skipping filtering.\n",
            "Node b32cf6cc-6bc7-4799-9880-457d399332b0 does not have a summary. Skipping filtering.\n",
            "Node e12d256e-46e8-463a-83d0-08a948ac1bf7 does not have a summary. Skipping filtering.\n",
            "Node f4031147-2bb6-466c-af05-71f2bb264c1d does not have a summary. Skipping filtering.\n",
            "Node 55fc0b9f-f9d1-4570-820a-6c4e2215bd48 does not have a summary. Skipping filtering.\n",
            "Node c8b2e10a-5c1e-4735-80d4-5dda833f16e2 does not have a summary. Skipping filtering.\n",
            "Node 9c93c336-6a12-4a7d-9ef7-5ff8cd767566 does not have a summary. Skipping filtering.\n",
            "Node 39937073-457a-46cc-9de0-3c33cbaeb9d1 does not have a summary. Skipping filtering.\n",
            "Node 43c985f8-a673-45c7-a991-b62587483b7d does not have a summary. Skipping filtering.\n",
            "Node 8506157c-f7f6-460f-a776-930361df643f does not have a summary. Skipping filtering.\n",
            "Node 45123dc6-f005-4610-bc53-92934af0d579 does not have a summary. Skipping filtering.\n",
            "Node 7c098e10-dd51-497e-b7cc-34038b9367f2 does not have a summary. Skipping filtering.\n",
            "Node d6c25af2-7636-43fd-a79c-58b716abcdc5 does not have a summary. Skipping filtering.\n",
            "Node 953060cc-a30f-49cc-b59c-92091819ef05 does not have a summary. Skipping filtering.\n",
            "Node 41435bb2-bc4a-4237-a1b1-dab635673b19 does not have a summary. Skipping filtering.\n",
            "Node b157e187-6e82-4d88-be7c-63198d518db7 does not have a summary. Skipping filtering.\n",
            "Node 3db07290-31d7-4f90-b385-5e230f82beed does not have a summary. Skipping filtering.\n",
            "Node d7ef775f-e68a-402f-9e0d-39e7f96181c9 does not have a summary. Skipping filtering.\n",
            "Node 1ef88208-234f-4a00-bc2b-cd67ab2a3f5d does not have a summary. Skipping filtering.\n",
            "Node ee9d87b5-b696-44fa-b600-4f1c2811d270 does not have a summary. Skipping filtering.\n",
            "Node 647358cf-5283-46b4-83fe-08fadf9308ea does not have a summary. Skipping filtering.\n",
            "Node 7c551b60-d863-4133-8df2-5e602f3e357c does not have a summary. Skipping filtering.\n",
            "Node 302929ef-d47d-4b74-b603-553d825ea799 does not have a summary. Skipping filtering.\n",
            "Node 2812d74a-2ed7-4e18-9319-f716fce76e41 does not have a summary. Skipping filtering.\n",
            "Node c7fec1ca-254a-4f9c-ae1d-75a7125f0905 does not have a summary. Skipping filtering.\n",
            "Node df7b47f9-af4a-4eba-874d-c24797733f76 does not have a summary. Skipping filtering.\n",
            "Node 22f939fe-30c8-49ad-b156-e20c69863e24 does not have a summary. Skipping filtering.\n",
            "Node d423e5fa-a536-423d-ab51-da7706bacd0f does not have a summary. Skipping filtering.\n",
            "Node cd519cc9-8efb-4332-bb1c-a4dd278ad926 does not have a summary. Skipping filtering.\n",
            "Node 715a0153-91fe-45c4-befc-ce5240db965f does not have a summary. Skipping filtering.\n",
            "Node 9e129f06-a7d3-42ce-a91b-30dc87d104a7 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe29aa3def0c4ef98efb7afaab16b74e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/217 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13f705419dcb42fe90cc5c32fd326073",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc13fe8aee164e9f825ed25a61818407",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "809a5353e287460293ee6e899c56893a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1b250a3131944e296c388fd6668db07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(documents, testset_size=50)\n",
        "dataset.to_pandas().to_csv('langchain_testset.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating retrievers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d0513a76dcf44068ef3a450f6b7896d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/306 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[5]: TimeoutError()\n",
            "Exception raised in Job[17]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[77]: TimeoutError()\n",
            "Exception raised in Job[89]: TimeoutError()\n",
            "Exception raised in Job[95]: TimeoutError()\n",
            "Exception raised in Job[101]: TimeoutError()\n",
            "Exception raised in Job[107]: TimeoutError()\n",
            "Exception raised in Job[113]: TimeoutError()\n",
            "Exception raised in Job[118]: TimeoutError()\n",
            "Exception raised in Job[119]: TimeoutError()\n",
            "Exception raised in Job[125]: TimeoutError()\n",
            "Exception raised in Job[131]: TimeoutError()\n",
            "Exception raised in Job[137]: TimeoutError()\n",
            "Exception raised in Job[142]: TimeoutError()\n",
            "Exception raised in Job[143]: TimeoutError()\n",
            "Exception raised in Job[149]: TimeoutError()\n",
            "Exception raised in Job[155]: TimeoutError()\n",
            "Exception raised in Job[161]: TimeoutError()\n",
            "Exception raised in Job[167]: TimeoutError()\n",
            "Exception raised in Job[173]: TimeoutError()\n",
            "Exception raised in Job[179]: TimeoutError()\n",
            "Exception raised in Job[184]: TimeoutError()\n",
            "Exception raised in Job[185]: TimeoutError()\n",
            "Exception raised in Job[191]: TimeoutError()\n",
            "Exception raised in Job[197]: TimeoutError()\n",
            "Exception raised in Job[203]: TimeoutError()\n",
            "Exception raised in Job[209]: TimeoutError()\n",
            "Exception raised in Job[215]: TimeoutError()\n",
            "Exception raised in Job[221]: TimeoutError()\n",
            "Exception raised in Job[227]: TimeoutError()\n",
            "Exception raised in Job[233]: TimeoutError()\n",
            "Exception raised in Job[239]: TimeoutError()\n",
            "Exception raised in Job[245]: TimeoutError()\n",
            "Exception raised in Job[251]: TimeoutError()\n",
            "Exception raised in Job[257]: TimeoutError()\n",
            "Exception raised in Job[263]: TimeoutError()\n",
            "Exception raised in Job[269]: TimeoutError()\n",
            "Exception raised in Job[275]: TimeoutError()\n",
            "Exception raised in Job[281]: TimeoutError()\n",
            "Exception raised in Job[287]: TimeoutError()\n",
            "Exception raised in Job[293]: TimeoutError()\n",
            "Exception raised in Job[299]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4105dccbbe8641fc867a33b48599d478",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/306 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[22]: TimeoutError()\n",
            "Exception raised in Job[52]: TimeoutError()\n",
            "Exception raised in Job[191]: ValueError(setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.)\n",
            "Exception raised in Job[269]: OutputParserException(Failed to parse NLIStatementOutput from completion null. Got: 1 validation error for NLIStatementOutput\n",
            "  Input should be a valid dictionary or instance of NLIStatementOutput [type=model_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n",
            "Exception raised in Job[280]: TimeoutError()\n",
            "Exception raised in Job[286]: TimeoutError()\n",
            "Exception raised in Job[292]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f736ce375ac64ad9b3eaeaecc3ac56f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/306 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[5]: TimeoutError()\n",
            "Exception raised in Job[11]: TimeoutError()\n",
            "Exception raised in Job[17]: TimeoutError()\n",
            "Exception raised in Job[23]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[65]: TimeoutError()\n",
            "Exception raised in Job[71]: TimeoutError()\n",
            "Exception raised in Job[77]: TimeoutError()\n",
            "Exception raised in Job[83]: TimeoutError()\n",
            "Exception raised in Job[89]: TimeoutError()\n",
            "Exception raised in Job[94]: TimeoutError()\n",
            "Exception raised in Job[95]: TimeoutError()\n",
            "Exception raised in Job[101]: TimeoutError()\n",
            "Exception raised in Job[107]: TimeoutError()\n",
            "Exception raised in Job[113]: TimeoutError()\n",
            "Exception raised in Job[118]: TimeoutError()\n",
            "Exception raised in Job[119]: TimeoutError()\n",
            "Exception raised in Job[125]: TimeoutError()\n",
            "Exception raised in Job[131]: TimeoutError()\n",
            "Exception raised in Job[137]: TimeoutError()\n",
            "Exception raised in Job[142]: TimeoutError()\n",
            "Exception raised in Job[143]: TimeoutError()\n",
            "Exception raised in Job[149]: TimeoutError()\n",
            "Exception raised in Job[154]: TimeoutError()\n",
            "Exception raised in Job[155]: TimeoutError()\n",
            "Exception raised in Job[161]: TimeoutError()\n",
            "Exception raised in Job[167]: TimeoutError()\n",
            "Exception raised in Job[173]: TimeoutError()\n",
            "Exception raised in Job[179]: TimeoutError()\n",
            "Exception raised in Job[184]: TimeoutError()\n",
            "Exception raised in Job[185]: TimeoutError()\n",
            "Exception raised in Job[191]: TimeoutError()\n",
            "Exception raised in Job[197]: TimeoutError()\n",
            "Exception raised in Job[202]: TimeoutError()\n",
            "Exception raised in Job[203]: TimeoutError()\n",
            "Exception raised in Job[208]: TimeoutError()\n",
            "Exception raised in Job[209]: TimeoutError()\n",
            "Exception raised in Job[215]: TimeoutError()\n",
            "Exception raised in Job[221]: TimeoutError()\n",
            "Exception raised in Job[227]: TimeoutError()\n",
            "Exception raised in Job[233]: TimeoutError()\n",
            "Exception raised in Job[239]: TimeoutError()\n",
            "Exception raised in Job[245]: TimeoutError()\n",
            "Exception raised in Job[251]: TimeoutError()\n",
            "Exception raised in Job[257]: TimeoutError()\n",
            "Exception raised in Job[263]: TimeoutError()\n",
            "Exception raised in Job[269]: TimeoutError()\n",
            "Exception raised in Job[274]: TimeoutError()\n",
            "Exception raised in Job[275]: TimeoutError()\n",
            "Exception raised in Job[281]: TimeoutError()\n",
            "Exception raised in Job[287]: TimeoutError()\n",
            "Exception raised in Job[292]: TimeoutError()\n",
            "Exception raised in Job[293]: TimeoutError()\n",
            "Exception raised in Job[298]: TimeoutError()\n",
            "Exception raised in Job[299]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "293a60937de74e988b4fb31aa3990836",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/306 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt n_l_i_statement_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "Exception raised in Job[227]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2923973cb7940a0bcd5f2b0e7e5a38d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/306 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[79]: OutputParserException(Invalid json output: {\n",
            "    \"statements\": [\n",
            "      \"The reviews provided do not mention joining the Army.\",\n",
            "      \"The reviews provided do not include any information about joining the Army.\",\n",
            "      \"The statement indicates that the reviews do not contain any references to joining the Army.\",\n",
            "      \"The statement \"Therefore, I do not know what the review says about that\" expresses a lack of information about the review's content regarding joining the Army.\"\n",
            "    ]\n",
            "  }\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n",
            "Exception raised in Job[4]: TimeoutError()\n",
            "Exception raised in Job[5]: TimeoutError()\n",
            "Exception raised in Job[11]: TimeoutError()\n",
            "Exception raised in Job[17]: TimeoutError()\n",
            "Exception raised in Job[23]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n",
            "Exception raised in Job[65]: TimeoutError()\n",
            "Exception raised in Job[71]: TimeoutError()\n",
            "Exception raised in Job[77]: TimeoutError()\n",
            "Exception raised in Job[89]: TimeoutError()\n",
            "Exception raised in Job[94]: TimeoutError()\n",
            "Exception raised in Job[95]: TimeoutError()\n",
            "Exception raised in Job[101]: TimeoutError()\n",
            "Exception raised in Job[107]: TimeoutError()\n",
            "Exception raised in Job[113]: TimeoutError()\n",
            "Exception raised in Job[118]: TimeoutError()\n",
            "Exception raised in Job[119]: TimeoutError()\n",
            "Exception raised in Job[124]: TimeoutError()\n",
            "Exception raised in Job[125]: TimeoutError()\n",
            "Exception raised in Job[131]: TimeoutError()\n",
            "Exception raised in Job[137]: TimeoutError()\n",
            "Exception raised in Job[143]: TimeoutError()\n",
            "Exception raised in Job[149]: TimeoutError()\n",
            "Exception raised in Job[155]: TimeoutError()\n",
            "Exception raised in Job[160]: TimeoutError()\n",
            "Exception raised in Job[161]: TimeoutError()\n",
            "Exception raised in Job[167]: TimeoutError()\n",
            "Exception raised in Job[172]: TimeoutError()\n",
            "Exception raised in Job[173]: TimeoutError()\n",
            "Exception raised in Job[178]: TimeoutError()\n",
            "Exception raised in Job[179]: TimeoutError()\n",
            "Exception raised in Job[184]: TimeoutError()\n",
            "Exception raised in Job[185]: TimeoutError()\n",
            "Exception raised in Job[191]: TimeoutError()\n",
            "Exception raised in Job[196]: TimeoutError()\n",
            "Exception raised in Job[197]: TimeoutError()\n",
            "Exception raised in Job[203]: TimeoutError()\n",
            "Exception raised in Job[209]: TimeoutError()\n",
            "Exception raised in Job[215]: TimeoutError()\n",
            "Exception raised in Job[220]: TimeoutError()\n",
            "Exception raised in Job[221]: TimeoutError()\n",
            "Exception raised in Job[227]: TimeoutError()\n",
            "Exception raised in Job[233]: TimeoutError()\n",
            "Exception raised in Job[239]: TimeoutError()\n",
            "Exception raised in Job[245]: TimeoutError()\n",
            "Exception raised in Job[251]: TimeoutError()\n",
            "Exception raised in Job[257]: TimeoutError()\n",
            "Exception raised in Job[263]: TimeoutError()\n",
            "Exception raised in Job[268]: TimeoutError()\n",
            "Exception raised in Job[269]: TimeoutError()\n",
            "Exception raised in Job[275]: TimeoutError()\n",
            "Exception raised in Job[281]: TimeoutError()\n",
            "Exception raised in Job[286]: TimeoutError()\n",
            "Exception raised in Job[287]: TimeoutError()\n",
            "Exception raised in Job[293]: TimeoutError()\n",
            "Exception raised in Job[299]: TimeoutError()\n",
            "Exception raised in Job[304]: TimeoutError()\n",
            "Exception raised in Job[305]: TimeoutError()\n"
          ]
        }
      ],
      "source": [
        "from ragas import EvaluationDataset, evaluate\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "chain_dict = {\n",
        "    \"naive\": naive_retrieval_chain,\n",
        "    \"bm25\": bm25_retrieval_chain,\n",
        "    # \"compression\": contextual_compression_retrieval_chain, #removed because Cohere was rate limitting me\n",
        "    \"multi_query\": multi_query_retrieval_chain,\n",
        "    \"parent_document\": parent_document_retrieval_chain,\n",
        "    \"ensemble\": ensemble_retrieval_chain,\n",
        "}\n",
        "\n",
        "ragas_results = {}\n",
        "\n",
        "for retriever_name, retriever in chain_dict.items():\n",
        "    config = RunnableConfig(\n",
        "        tags=[f\"{retriever_name}\"]\n",
        "    )\n",
        "    for test_row in dataset:\n",
        "        response = retriever.invoke({\"question\" : test_row.eval_sample.user_input}, config=config) # I definitely could have done this faster with batching\n",
        "        test_row.eval_sample.response = response[\"response\"].content\n",
        "        test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "    dataset.to_pandas().to_csv(f'langchain_testset_{retriever_name}.csv', index=False)\n",
        "    evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "    ragas_results[retriever_name] = evaluate(\n",
        "        dataset=evaluation_dataset,\n",
        "        metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "        llm=generator_llm) #using same llm for evaluation as for generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "naive\n",
            "{'context_recall': 0.9804, 'faithfulness': 0.9660, 'factual_correctness(mode=f1)': 0.6759, 'answer_relevancy': 0.9191, 'context_entity_recall': 0.4733, 'noise_sensitivity(mode=relevant)': 0.2628}\n",
            "bm25\n",
            "{'context_recall': 0.9673, 'faithfulness': 0.8977, 'factual_correctness(mode=f1)': 0.6563, 'answer_relevancy': 0.9204, 'context_entity_recall': 0.4754, 'noise_sensitivity(mode=relevant)': 0.2921}\n",
            "multi_query\n",
            "{'context_recall': 0.9902, 'faithfulness': 0.9563, 'factual_correctness(mode=f1)': 0.6680, 'answer_relevancy': 0.9157, 'context_entity_recall': 0.4851, 'noise_sensitivity(mode=relevant)': 0.1667}\n",
            "parent_document\n",
            "{'context_recall': 0.9690, 'faithfulness': 0.8399, 'factual_correctness(mode=f1)': 0.6355, 'answer_relevancy': 0.8988, 'context_entity_recall': 0.4430, 'noise_sensitivity(mode=relevant)': 0.2748}\n",
            "ensemble\n",
            "{'context_recall': 0.9618, 'faithfulness': 0.9811, 'factual_correctness(mode=f1)': 0.7116, 'answer_relevancy': 0.8823, 'context_entity_recall': 0.4562, 'noise_sensitivity(mode=relevant)': 0.7500}\n"
          ]
        }
      ],
      "source": [
        "for retriever_name, results in ragas_results.items():\n",
        "    print(retriever_name)\n",
        "    print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cost and latency metrics from LangSmith:\n",
        "\n",
        "| Retriever | Median Tokens | P50 | P99 |\n",
        "|-----------|---------------|-----|-----|\n",
        "| Naive | 3,766  | 4.62s  | 9.25s |\n",
        "| BM25 | 1,626 | 2.95s | 6.88s |\n",
        "| Multi Query | 5,117 | 8.03s | 29.39s!! |\n",
        "| Parent Doc | 821 | 2.53s | 5.96s |\n",
        "| Ensemble | 5,905 | 8.52s | 13.54s |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discussion\n",
        "\n",
        "The results were quite surprising. The naive retriever had the highest context recall and close to the highest answer relevancy. Overall, the performance results were quite mixed. Which is best depends on cost and latency considerations. For example, the parent document retriever has some of the loweset results on RAGAS, but it was very fast and used only a median of 821 tokens (due to only one document being retrieved). On the other hand, the ensemble retriever has much better RAGAS scores but used the most tokens on average and had the highest median latency. I would suggest experimenting with increasing k for the parent document retriever to find a sweet-spot between performance and cost/latency."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
